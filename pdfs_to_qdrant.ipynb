{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Automate the ingestion and organization of PDF documents, their pages, and associated metadata, into a Qdrant vector database for later retrieval and analysis.\n",
    "\n",
    "This script ingests PDF documents from a specified directory, extracts both document-level metadata and page-level content, storing it in a Qdrant vector database using two separate collections:\n",
    "    - PDF_document: metadata about the PDF files-- such as title, page count, creation date, and document summary-- along with a vectorized version of the summary\n",
    "    - PDF_document_page: Contains the text content of individual pages along with their page number and a reference to the associated PDF document.\n",
    "\n",
    "Key functionality includes:\n",
    "    \n",
    "**Library Catalog Ingestion**:\n",
    "    - Loads a library catalog (Excel file) containing metadata for the PDFs into a pandas DataFrame.\n",
    "    - Processes specific date columns into a standardized format (Zulu time).\n",
    "\n",
    "**PDF Processing**:\n",
    "    - Walks through the specified directory, identifying PDF files.\n",
    "    - For each PDF, computes a unique document ID, retrieves corresponding metadata from the DataFrame, and stores the metadata in the `PDF_document` collection.\n",
    "    - For each page of the PDF, extracts the content and stores it in the `PDF_document_page` collection with a reference to the PDF document.\n",
    "\n",
    "\n",
    "Usage:\n",
    "    1. Ensure that the environment variables for Weaviate credentials (QDRANT_API_KEY, QDRANT_URL, OPENAI_API_KEY) are set.\n",
    "    2. Place the PDF files in the specified `pdf_source_dir`.\n",
    "    3. Ensure metadata.xlsx is present in `metadata_dir`.\n",
    "    4. Run the script to upload the PDF metadata and page content to he collections\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installs, Imports and Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T20:18:10.873669Z",
     "start_time": "2024-04-19T20:18:10.319647Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, PayloadSchemaType\n",
    "from qdrant_client.http import exceptions as qdrant_exceptions\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T20:18:11.767Z",
     "start_time": "2024-04-19T20:18:11.764358Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''This litle code block is used anytime you want to import a local module from within a Jupyter Notebook. This is required becuase Jupyter treats each cell as a module.'''\n",
    "\n",
    "# Navigate up one level from the current notebook's directory to reach the root directory\n",
    "current_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Set Configurations and Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = st.secrets[\"QDRANT_API_KEY\"]\n",
    "url = st.secrets[\"QDRANT_URL\"]\n",
    "\n",
    "\n",
    "client = QdrantClient(\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T20:18:17.535466Z",
     "start_time": "2024-04-19T20:18:17.532838Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf_source_dir = \"./docs/pdfs/\"\n",
    "metadata_file_path = \"./docs/metadata/metadata.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm access to the Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='ask_pdf_pages'), CollectionDescription(name='ask_pdf_docs'), CollectionDescription(name='ASK_vectorstore')]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pdfs_collection = client.get_collections()  # \"ask_pdf_docs\"\n",
    "    # pages_collection = client.get_collections(\"ask_pdf_pages\")\n",
    "    print(pdfs_collection)\n",
    "    # print(pages_collection)\n",
    "except qdrant_exceptions.UnexpectedResponse as e:\n",
    "    # Check if the error is a 404 Not Found\n",
    "    if \"404\" in str(e):\n",
    "        print(\"The server returned a 404 Not Found error, which indicates the server is active but could not find the requested URL or endpoint. This might be due to a wrong URL, an incorrect path, or a resource that doesn't exist.\")\n",
    "    else:\n",
    "        # Re-raise the error if it's not a 404\n",
    "        raise\n",
    "except Exception as e:\n",
    "    # Handle any other exceptions that may occur\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Metadata from Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T20:20:42.235955Z",
     "start_time": "2024-04-19T20:20:42.189093Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported: ./docs/metadata/metadata.xlsx\n"
     ]
    }
   ],
   "source": [
    "datetime_cols = ['creation_date', 'effective_date',\n",
    "                 'upsert_date', 'expiration_date']\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(metadata_file_path)\n",
    "\n",
    "    for col in datetime_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce', utc=True).dt.strftime(\n",
    "                '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    df = df.apply(lambda col: col.astype(str).fillna(\n",
    "        '') if col.dtype == 'float64' else col.fillna(''))\n",
    "\n",
    "    print(f\"Successfully imported: {metadata_file_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    os.write(1, f\"Failed to read the metadata file: {e}\\n\".encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T20:20:57.522564Z",
     "start_time": "2024-04-19T20:20:45.651904Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# starter code that pulls the library catalog into pdfs_collection\n",
    "\n",
    "import pypdf\n",
    "import json\n",
    "from langchain.community.document_loaders import PyPDFLoader\n",
    "import utils  # Ensure utils module with compute_doc_id function is imported\n",
    "\n",
    "pdfs_collection = client.collections.get(\"PDF_document\")\n",
    "pdf_pages_collection = client.collections.get(\"PDF_document_page\")\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path, df):\n",
    "    try:\n",
    "        # Compute the document_id for the PDF\n",
    "        document_id = str(utils.compute_doc_id(pdf_path))\n",
    "\n",
    "        # Find the metadata row in df that corresponds to this document_id\n",
    "        pdf_metadata = df[df['document_id'] == str(document_id)]\n",
    "\n",
    "        if not pdf_metadata.empty:\n",
    "            if len(pdf_metadata) > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Found duplicates for document_id: '{document_id}', number of results: {len(pdf_metadata)}\")\n",
    "            pdf_metadata = pdf_metadata.iloc[0]\n",
    "            properties = pdf_metadata.to_dict()\n",
    "            if \"publication_number\" in properties:\n",
    "                properties['publication_number'] = str(properties['publication_number'])\n",
    "            pdfs_collection.data.insert(\n",
    "                properties=properties,\n",
    "                uuid=document_id\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"No metadata found for document ID: {document_id}\")\n",
    "\n",
    "        # Process PDF pages. I believe this is just the metadata/payload, not the embeddings\n",
    "        pages_objects = []\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        for page in loader.load():\n",
    "            pages_objects.append(\n",
    "                wvc.data.DataObject(\n",
    "                    properties={\n",
    "                        \"title\": properties['title'],\n",
    "                        \"publication_number\": str(properties['publication_number']),\n",
    "                        \"content\": page.page_content,\n",
    "                        \"page_number\": page.metadata[\"page\"],\n",
    "                    },\n",
    "                    references={\n",
    "                        \"hasPdfDocument\": document_id\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        pdf_pages_collection.data.insert_many(pages_objects)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {pdf_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "print(\"Loading PDFs from directory...\")\n",
    "\n",
    "for folder_name, sub_folders, filenames in os.walk(pdf_source_dir):\n",
    "    for file in filenames:\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            process_pdf(os.path.join(folder_name, file), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
